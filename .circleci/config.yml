version: 2.1

orbs:
  kubernetes: circleci/kubernetes@1.3.0

commands:
  destroy-environment:
    description: Destroy frontend CloudFormation stack and resources given a workflow ID.
    parameters:
      WorkflowID:
        type: string
    steps:
      - run:
          name: Destroy environments
          when: on_fail
          command: |
            echo "Destroying environment: << parameters.WorkflowID >> "
            echo "Empty S3 bucket for static frontend website..."
            aws s3 rm "s3://website-<< parameters.WorkflowID >>" --recursive
            echo "Delete S3 bucket for static frontend website..."
            aws cloudformation delete-stack --stack-name capstone-website-<< parameters.WorkflowID >>

  revert-cluster:
    description: Delete K8s deployment and point service to old deployment.
    parameters:
      WorkflowID:
        type: string
    steps:
      - kubernetes/install-kubectl:
          when: on_fail
      - run:
          name: Revert K8s resources
          when: on_fail
          command: |
            # Update kubectl to point to EKS cluster
            aws eks update-kubeconfig --name cluster-$UUID
            echo "Delete new deployment..."
            kubectl delete deploy capstone-deployment-${CIRCLE_WORKFLOW_ID:0:7}
            echo "Update service selector to old deployment..."
            export OLD_ID="$(curl https://kvdb.io/$KVDB_BUCKET_ID/old_id -u $KVDB_READ_KEY:$KVDB_READ_KEY)"
            sed -i -e 's/${CIRCLE_WORKFLOW_ID:0:7}/$OLD_ID/g' ./backend/backend-service.yaml
            kubectl apply -f /backend/backend-service.yaml

jobs:
  lint-code:
    docker:
      - image: python:3.7.3-stretch
    steps:
      - checkout
      - run:
          name: Lint code
          command: |
            # a call of 'make install' would need 'npm' to be installed first which is not necessary for linting.
            pip install --upgrade pip && pip install -r backend/src/requirements.txt
            make install_hadolint
            make lint

  build-frontend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: [frontend-build]
      - run:
          name: Build frontend
          command: |
            cd frontend
            npm install
            npm run build
      - save_cache:
          paths: [frontend/node_modules]
          key: frontend-build

  build-backend:
    docker:
      - image: docker
    steps:
      - checkout
      - setup_remote_docker:
          docker_layer_caching: true
      - run:
          name: Install bash
          command: |
            apk add bash
      - run:
          name: Build backend
          command: |
            docker build --tag udacity-project ./backend

  test-frontend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: [frontend-build]
      - run:
          name: Test frontend
          command: |
            cd frontend
            npm install
            npm test -- a

  test-backend:
    machine:
      image: ubuntu-1604:202007-01 # Use machine executor instead of Docker executor to avoid a container-in-container environment for the backend test.
    steps:
      - checkout
      - run:
          name: Install dependencies
          command: |
            sudo apt-get update
            sudo apt-get upgrade -y

            # Install minikube
            curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
            sudo install minikube-linux-amd64 /usr/local/bin/minikube
            rm minikube-linux-amd64
      - kubernetes/install-kubectl
      - run:
          name: Set environment variables
          command: |
            echo DATABASE_USERNAME="$DATABASE_USERNAME" | sudo tee -a /etc/environment > /dev/null
            echo DATABASE_PASSWORD="$DATABASE_PASSWORD" | sudo tee -a /etc/environment > /dev/null
            echo DATABASE_NAME="$DATABASE_NAME" | sudo tee -a /etc/environment > /dev/null
            echo DATABASE_HOST="$DATABASE_HOST" | sudo tee -a /etc/environment > /dev/null
            echo DATABASE_PORT="$DATABASE_PORT" | sudo tee -a /etc/environment > /dev/null
      - run:
          name: Test backend in Docker container
          command: |
            docker build --tag udacity-project ./backend
            export CONTAINER_ID="$(docker run --rm -d -p 80:8000 --env-file /etc/environment --name udacity-app udacity-project)"
            echo "CONTAINER_ID: $CONTAINER_ID"

            export API_URL_DOCKER="localhost/api/wisdom"
            echo "API_URL_DOCKER: $API_URL_DOCKER"

            echo "Wait 20 s until Docker container is properly running..."
            sleep 20s

            if curl $API_URL_DOCKER | grep "categories"; then
              echo SUCCESS
            else
              echo FAIL
              exit 1
            fi

            if curl $API_URL_DOCKER | grep "image-urls"; then
              echo SUCCESS
            else
              echo FAIL
              exit 1
            fi

            if curl $API_URL_DOCKER | grep "source"; then
              echo SUCCESS
            else
              echo FAIL
              exit 1
            fi

            if curl $API_URL_DOCKER | grep "wisdom"; then
              echo SUCCESS
            else
              echo FAIL
              exit 1
            fi

            docker stop $CONTAINER_ID
      - run:
          name: Upload Docker image to repository
          command: |
            echo "Upload and tag Docker image with new workflow ID..."
            ./scripts/upload_docker.sh ${CIRCLE_WORKFLOW_ID:0:7}
      - run:
          name: Test backend in Minikube
          command: |
            ./scripts/run_kubernetes_minikube.sh

            export API_URL_K8S="$(minikube service $(minikube service list | grep -o -e "\S*capstone\S*") --url=true)/api/wisdom"
            echo "API_URL_K8S: $API_URL_K8S"

            if curl $API_URL_K8S | grep "categories"; then
              echo SUCCESS
            else
              echo FAIL
              exit 1
            fi

            if curl $API_URL_K8S | grep "image-urls"; then
              echo SUCCESS
            else
              echo FAIL
              exit 1
            fi

            if curl $API_URL_K8S | grep "source"; then
              echo SUCCESS
            else
              echo FAIL
              exit 1
            fi

            if curl $API_URL_K8S | grep "wisdom"; then
              echo SUCCESS
            else
              echo FAIL
              exit 1
            fi

            minikube stop

  deploy-infrastructure:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Create S3 bucket for static frontend website
          command: |
            aws cloudformation deploy \
              --stack-name "capstone-website-${CIRCLE_WORKFLOW_ID:0:7}" \
              --template-file .circleci/files/frontend-bucket.yaml \
              --parameter-overrides WorkflowID="${CIRCLE_WORKFLOW_ID:0:7}" \
              --tags project=capstone
      - destroy-environment:
          WorkflowID: ${CIRCLE_WORKFLOW_ID:0:7}

  deploy-backend:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - kubernetes/install-kubectl
      - run:
          name: Deploy backend
          command: |
            echo "Update deployment and service..."
            aws eks update-kubeconfig --name cluster-$UUID

            echo "Get old id from current deployment name..."
            export OLD_ID=$(kubectl get deploy -o name | grep -o -e ".*capstone.*" | sed 's/^.*capstone-deployment-//') # use 'sed' to replace everything with empty string except the id
            echo "OLD_ID: $OLD_ID"
            echo "Write old id to KVdb bucket..."
            curl https://kvdb.io/$KVDB_BUCKET_ID/old_id -d "$OLD_ID" -u $KVDB_WRITE_KEY:$KVDB_WRITE_KEY

            echo "Update workflow id in deployment..."
            sed -i -e 's/$UUID/${CIRCLE_WORKFLOW_ID:0:7}/g' ./backend/backend-deployment.yaml
            cat ./backend/backend-deployment.yaml

            echo "Update service selector to new deployment (replace id by new workflow id)..."
            sed -i -e 's/$UUID/${CIRCLE_WORKFLOW_ID:0:7}/g' ./backend/backend-service.yaml
            cat ./backend/backend-service.yaml

            echo "Apply new deployment and updated service..."
            ./scripts/run_kubernetes_eks.sh
      - run:
          name: Fetch and save LoadBalancer URL of K8s service
          command: |
            export LOADBALANCER_URL="http://$(kubectl get $(kubectl get svc -o name | grep -o -e ".*capstone.*") --output jsonpath='{.status.loadBalancer.ingress[0].hostname}'):8000"
            echo "LOADBALANCER_URL: $LOADBALANCER_URL"
            curl https://kvdb.io/$KVDB_BUCKET_ID/LoadBalancer_Url -d "$LOADBALANCER_URL" -u $KVDB_WRITE_KEY:$KVDB_WRITE_KEY
      - destroy-environment:
          WorkflowID: ${CIRCLE_WORKFLOW_ID:0:7}
      - revert-cluster:
          WorkflowID: ${CIRCLE_WORKFLOW_ID:0:7}

  deploy-frontend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: [frontend-build]
      - run:
          name: Install dependencies
          command: |
            sudo apt update
            sudo apt upgrade -y
            sudo apt install -y awscli
      - run:
          name: Deploy frontend website
          command: |
            export LOADBALANCER_URL="$(curl https://kvdb.io/$KVDB_BUCKET_ID/LoadBalancer_Url -u $KVDB_READ_KEY:$KVDB_READ_KEY)"
            echo "LOADBALANCER_URL: $LOADBALANCER_URL"
            echo REACT_APP_HOST="$LOADBALANCER_URL" > frontend/.env.production
            cat frontend/.env.production
            cd frontend
            npm install
            npm run build
            aws s3 cp build s3://website-${CIRCLE_WORKFLOW_ID:0:7} --recursive
      - destroy-environment:
          WorkflowID: ${CIRCLE_WORKFLOW_ID:0:7}

  smoke-test:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - run:
          name: Install dependencies
          command: |
            sudo apt update
            sudo apt upgrade -y
            sudo apt install -y curl
            sudo apt install -y awscli
            aws --version
      - run:
          name: Backend smoke test
          command: |
            export LOADBALANCER_URL="$(curl https://kvdb.io/$KVDB_BUCKET_ID/LoadBalancer_Url -u $KVDB_READ_KEY:$KVDB_READ_KEY)"
            export API_URL="$LOADBALANCER_URL/api/wisdom"
            echo "API_URL: $API_URL"

            if curl $API_URL | grep "categories"; then
              echo SUCCESS
            else
              echo FAIL
              exit 1
            fi

            if curl $API_URL | grep "image-urls"; then
              echo SUCCESS
            else
              echo FAIL
              exit 1
            fi

            if curl $API_URL | grep "source"; then
              echo SUCCESS
            else
              echo FAIL
              exit 1
            fi

            if curl $API_URL | grep "wisdom"; then
              echo SUCCESS
            else
              echo FAIL
              exit 1
            fi
      - run:
          name: Frontend smoke test
          command: |
            export URL="http://website-${CIRCLE_WORKFLOW_ID:0:7}.s3-website.${AWS_DEFAULT_REGION}.amazonaws.com"
            echo "Frontend URL: $URL"

            if curl $URL | grep "GetWise"; then
              echo SUCCESS
              exit 0
            else
              echo FAIL
              exit 1
            fi
      - destroy-environment:
          WorkflowID: ${CIRCLE_WORKFLOW_ID:0:7}
      - revert-cluster:
          WorkflowID: ${CIRCLE_WORKFLOW_ID:0:7}

  cloudfront-update:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Install dependencies
          command: |
            yum update -y
            yum install -y curl
            aws --version
      - run:
          name: Update cloudfront distribution
          command: |
            aws cloudformation deploy \
              --template-file .circleci/files/cloudfront.yaml \
              --stack-name capstone-cloudfront-$UUID \
              --parameter-overrides WorkflowID="${CIRCLE_WORKFLOW_ID:0:7}" \
              --tags project=capstone
      - destroy-environment:
          WorkflowID: ${CIRCLE_WORKFLOW_ID:0:7}
      - revert-cluster:
          WorkflowID: ${CIRCLE_WORKFLOW_ID:0:7}

  cleanup:
    docker:
      - image: amazon/aws-cli
    steps:
      - kubernetes/install-kubectl
      - run:
          name: Remove old stacks and cluster resources
          command: |
            export OLD_ID="$(curl https://kvdb.io/$KVDB_BUCKET_ID/old_id -u $KVDB_READ_KEY:$KVDB_READ_KEY)"
            echo "Destroying environment: $OLD_ID"

            echo "Empty S3 bucket for static frontend website..."
            aws s3 rm "s3://website-$OLD_ID" --recursive
            echo "Delete S3 bucket for static frontend website..."
            aws cloudformation delete-stack --stack-name capstone-website-$OLD_ID

            aws eks update-kubeconfig --name cluster-$UUID
            echo "Delete old deployment..."
            kubectl delete deploy capstone-deployment-$OLD_ID


workflows:
  default:
    jobs:
      - lint-code
      - build-frontend:
          requires: [lint-code]
      - build-backend:
          requires: [lint-code]
      - test-frontend:
          requires: [build-frontend]
      - test-backend:
          requires: [build-backend]
      - deploy-infrastructure:
          requires: [test-frontend, test-backend]
          filters:
            branches:
              only: [main]
      - deploy-backend:
          requires: [deploy-infrastructure]
      - deploy-frontend:
          requires: [deploy-backend]
      - smoke-test:
          requires: [deploy-backend, deploy-frontend]
      - cloudfront-update:
          requires: [smoke-test]
      - cleanup:
          requires: [cloudfront-update]
